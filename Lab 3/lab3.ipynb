{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. \n",
    "Data exploration\n",
    "Explore the three datasets. Use your judgment as a human being to describe\n",
    "what makes you able to tell spam apart from ham. Also explore the differences between the two classes of ham (easy and hard ham). What makes them different? Write approximately one paragraph.\n",
    "\n",
    "1. ##### Difference between Ham and Spam\n",
    "    Spam contains a lot of clickbaity titles with links that looks more than suspicious. Very sensational language and the senders adress looks very auto-generated for example: sabrina@mx3.1premio.com.\n",
    "    Ham on the other hand is more legit and the emails looks like they are sent from either real people or real companies with a newsletter and you get the choice to unsubscribe or not.\n",
    "\n",
    "2. ##### Difference between Hard and Easy Ham\n",
    "    Easy ham seems to be mostly conversations between real life people, not alot of code, mostly natural speaking language\n",
    "    Hard Ham contains more code, and contains mostly of commercials which makes it hard to judge if it's actually wanted by the reciever or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.\n",
    "Perform an appropriate train-test split on the each of the datasets. We will use\n",
    "the training sets to train a classifier, and evaluate its performance against the\n",
    "test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305    b'From farwood944@awod.com  Sat Sep 14 16:20:3...\n",
      "341    b'Return-Path: ler@lerami.lerctr.org\\nDelivery...\n",
      "47     b'From checkoutthesefreakhugecocksinapussy@fra...\n",
      "67     b'From cweqx@dracnet.es  Mon Aug 26 15:14:56 2...\n",
      "358    b'From bralbertini21@netscape.net  Tue Sep 17 ...\n",
      "                             ...                        \n",
      "41     b'Received: from qrq.cc.ntu.edu.tw (giga.tw.fr...\n",
      "159    b'From iiu-owner@taint.org  Thu Aug 29 11:09:1...\n",
      "292    b'From fholland@bigfoot.com  Wed Sep 11 19:43:...\n",
      "132    b'From rxwi506@framesetup.com  Wed Aug 28 10:4...\n",
      "291    b'From akad5@excite.com  Wed Sep 11 16:06:24 2...\n",
      "Length: 126, dtype: object\n",
      "305    spam\n",
      "341    spam\n",
      "47     spam\n",
      "67     spam\n",
      "358    spam\n",
      "       ... \n",
      "41     spam\n",
      "159    spam\n",
      "292    spam\n",
      "132    spam\n",
      "291    spam\n",
      "Length: 126, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setting the random state to 1 to ensure reproducibility\n",
    "RANDOM_STATE = 1\n",
    "\n",
    "# Creating lists and dicts to parse the text files\n",
    "easy_ham_texts: list[str] = []\n",
    "hard_ham_texts: list[str] = []\n",
    "spam_texts: list[str] = []\n",
    "easy_ham_labels: list[str] = []\n",
    "hard_ham_labels: list[str] = []\n",
    "spam_labels: list[str] = []\n",
    "easy_ham_dir_path = os.getcwd() + \"/20021010_easy_ham/easy_ham/\"\n",
    "hard_ham_dir_path = os.getcwd() + \"/20021010_hard_ham/hard_ham/\"\n",
    "spam_dir_path = os.getcwd() + \"/20021010_spam/spam/\"\n",
    "\n",
    "# Parsing the text files into lists\n",
    "for file_name in os.listdir(easy_ham_dir_path):\n",
    "    f = open(easy_ham_dir_path+file_name, \"rb\")\n",
    "    text = f.read()\n",
    "    easy_ham_texts.append(text)\n",
    "    easy_ham_labels.append(\"easy_ham\")\n",
    "    f.close()\n",
    "\n",
    "for file_name in os.listdir(hard_ham_dir_path):\n",
    "    f = open(hard_ham_dir_path+file_name, \"rb\")\n",
    "    text = f.read()\n",
    "    hard_ham_texts.append(text)\n",
    "    hard_ham_labels.append(\"hard_ham\")\n",
    "    f.close()\n",
    "\n",
    "for file_name in os.listdir(spam_dir_path):\n",
    "    f = open(spam_dir_path+file_name, \"rb\")\n",
    "    text = f.read()\n",
    "    spam_texts.append(text)\n",
    "    spam_labels.append(\"spam\")\n",
    "    f.close()\n",
    "\n",
    "# Making the lists series for nicer printing\n",
    "easy_ham_texts = pd.Series(easy_ham_texts)\n",
    "hard_ham_texts = pd.Series(hard_ham_texts)\n",
    "spam_texts = pd.Series(spam_texts)\n",
    "easy_ham_labels = pd.Series(easy_ham_labels)\n",
    "hard_ham_labels = pd.Series(hard_ham_labels)\n",
    "spam_labels = pd.Series(spam_labels)\n",
    "\n",
    "# Make a simple train-test split using 25% of the data for testing as this was recommended in last thursday's lecture\n",
    "\n",
    "# Easy Ham:\n",
    "easy_ham_x_train, easy_ham_x_test, easy_ham_y_train, easy_ham_y_test = train_test_split(easy_ham_texts, easy_ham_labels, test_size=0.25, random_state=RANDOM_STATE)\n",
    "\n",
    "# Hard Ham:\n",
    "hard_ham_x_train, hard_ham_x_test, hard_ham_y_train, hard_ham_y_test = train_test_split(hard_ham_texts, hard_ham_labels, test_size=0.25, random_state=RANDOM_STATE)\n",
    "\n",
    "# Spam:\n",
    "spam_x_train, spam_x_test, spam_y_train, spam_y_test = train_test_split(spam_texts, spam_labels, test_size=0.25, random_state=RANDOM_STATE)\n",
    "\n",
    "print(spam_x_test)\n",
    "print(spam_y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
